{"ast":null,"code":"var _jsxFileName = \"/Users/nico/Code/dreister_api/frontend/components/Page.js\";\nimport React from \"react\";\nvar __jsx = React.createElement;\nimport fetch from 'node-fetch';\nimport { useEffect, useState } from 'react';\nimport { ScrapeProvider } from './scrapeContext'; //custom hook!\n\nfunction useRemainingScrapes() {\n  const {\n    0: remainingScrapes,\n    1: setRemainingScrapes\n  } = useState(0); // Use effect accept only a function as parameter\n\n  useEffect(function () {\n    (async () => {\n      const res = await fetch('http://localhost:3000/api/ramaining-scrapes');\n      const data = await res.json();\n      setRemainingScrapes(data);\n    })();\n  }, []);\n  return remainingScrapes;\n}\n\nfunction useScrapes() {\n  const {\n    0: scrapes,\n    1: setScrapes\n  } = useState([{\n    instagramId: ''\n  }]); // Use effect accept only a function as parameter\n\n  useEffect(function () {\n    (async () => {\n      console.log('Mounting or Updating');\n      const res = await fetch('http://localhost:3000/api/top100');\n      const data = await res.json();\n      setScrapes(data);\n    })();\n  }, []);\n  return scrapes;\n}\n\nconst Page = ({\n  children\n}) => {\n  const scrapes = useScrapes();\n  const remainingScrapes = useRemainingScrapes();\n  return __jsx(ScrapeProvider, {\n    value: {\n      scrapes,\n      remainingScrapes\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 39,\n      columnNumber: 5\n    }\n  }, __jsx(\"div\", {\n    className: \"page\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 42,\n      columnNumber: 7\n    }\n  }, children));\n};\n\nexport default Page;","map":{"version":3,"sources":["/Users/nico/Code/dreister_api/frontend/components/Page.js"],"names":["fetch","useEffect","useState","ScrapeProvider","useRemainingScrapes","remainingScrapes","setRemainingScrapes","res","data","json","useScrapes","scrapes","setScrapes","instagramId","console","log","Page","children"],"mappings":";;;AAAA,OAAOA,KAAP,MAAkB,YAAlB;AACA,SAASC,SAAT,EAAoBC,QAApB,QAAoC,OAApC;AACA,SAASC,cAAT,QAA+B,iBAA/B,C,CAEA;;AACA,SAASC,mBAAT,GAA+B;AAC7B,QAAM;AAAA,OAACC,gBAAD;AAAA,OAAmBC;AAAnB,MAA0CJ,QAAQ,CAAC,CAAD,CAAxD,CAD6B,CAE7B;;AACAD,EAAAA,SAAS,CAAC,YAAY;AACpB,KAAC,YAAY;AACX,YAAMM,GAAG,GAAG,MAAMP,KAAK,CAAC,6CAAD,CAAvB;AACA,YAAMQ,IAAI,GAAG,MAAMD,GAAG,CAACE,IAAJ,EAAnB;AACAH,MAAAA,mBAAmB,CAACE,IAAD,CAAnB;AACD,KAJD;AAKD,GANQ,EAMN,EANM,CAAT;AAOA,SAAOH,gBAAP;AACD;;AAGD,SAASK,UAAT,GAAsB;AACpB,QAAM;AAAA,OAACC,OAAD;AAAA,OAAUC;AAAV,MAAwBV,QAAQ,CAAC,CAAC;AAAEW,IAAAA,WAAW,EAAE;AAAf,GAAD,CAAD,CAAtC,CADoB,CAGpB;;AACAZ,EAAAA,SAAS,CAAC,YAAY;AACpB,KAAC,YAAY;AACXa,MAAAA,OAAO,CAACC,GAAR,CAAY,sBAAZ;AACA,YAAMR,GAAG,GAAG,MAAMP,KAAK,CAAC,kCAAD,CAAvB;AACA,YAAMQ,IAAI,GAAG,MAAMD,GAAG,CAACE,IAAJ,EAAnB;AACAG,MAAAA,UAAU,CAACJ,IAAD,CAAV;AACD,KALD;AAMD,GAPQ,EAON,EAPM,CAAT;AAQA,SAAOG,OAAP;AACD;;AAED,MAAMK,IAAI,GAAG,CAAC;AAAEC,EAAAA;AAAF,CAAD,KAAkB;AAC7B,QAAMN,OAAO,GAAGD,UAAU,EAA1B;AACA,QAAML,gBAAgB,GAAGD,mBAAmB,EAA5C;AACA,SACE,MAAC,cAAD;AAAgB,IAAA,KAAK,EACnB;AAAEO,MAAAA,OAAF;AAAWN,MAAAA;AAAX,KADF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAGE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACGY,QADH,CAHF,CADF;AASD,CAZD;;AAcA,eAAeD,IAAf","sourcesContent":["import fetch from 'node-fetch';\nimport { useEffect, useState } from 'react';\nimport { ScrapeProvider } from './scrapeContext';\n\n//custom hook!\nfunction useRemainingScrapes() {\n  const [remainingScrapes, setRemainingScrapes] = useState(0)\n  // Use effect accept only a function as parameter\n  useEffect(function () {\n    (async () => {\n      const res = await fetch('http://localhost:3000/api/ramaining-scrapes')\n      const data = await res.json()\n      setRemainingScrapes(data)\n    })()\n  }, [])\n  return remainingScrapes\n}\n\n\nfunction useScrapes() {\n  const [scrapes, setScrapes] = useState([{ instagramId: '' }])\n\n  // Use effect accept only a function as parameter\n  useEffect(function () {\n    (async () => {\n      console.log('Mounting or Updating')\n      const res = await fetch('http://localhost:3000/api/top100')\n      const data = await res.json()\n      setScrapes(data)\n    })()\n  }, [])\n  return scrapes\n}\n\nconst Page = ({ children }) => {\n  const scrapes = useScrapes();\n  const remainingScrapes = useRemainingScrapes();\n  return (\n    <ScrapeProvider value={\n      { scrapes, remainingScrapes }\n    }>\n      <div className=\"page\">\n        {children}\n      </div>\n    </ScrapeProvider>\n  );\n}\n\nexport default Page;\n"]},"metadata":{},"sourceType":"module"}